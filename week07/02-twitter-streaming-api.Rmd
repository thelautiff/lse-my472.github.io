---
title: "Twitter's Streaming API"
output: github_document
---

#### Authenticating

Before running this file yourself, you need to submit an application for a Twitter developer account which make take a few days to be processed. Follow the instructions in the slides to submit such an application and let us know on Slack under #twitterapi if you are having any problems.



Before we can start collecting Twitter data, we need to create an OAuth token that will allow us to authenticate our connection and access our personal data.

After the new API changes, getting a new token requires submitting an application for a developer account, which may take a few days. So for now we will assume that we have access to one. See the instructions at the end of the file for how to create yours once your application is approved. We'll come back to this during the seminars this week.

This will not work in your computer!

```{r}
library("rtweet")
```

Once you have created your token (after your application has been approved), you can check that it worked by running the line below:

```{r}

load("my_authentication.rda")
# Replace the app name with your own!

# replace the app name with your own!
twitter_token <- create_token(app = "Research 2020/21", 
                              consumer_key = authentication$consumer_key,
                              consumer_secret = authentication$consumer_secret,
                              access_token = authentication$access_token,
                              access_secret = authentication$access_token_secret)

lookup_users("LSEnews")$screen_name
```

If this displays `LSEnews` then we're good to go!

First, let us have a look at the stream_tweets function which we will use a lot.



#### Collecting data from Twitter's Streaming API

Collecting tweets filtering by keyword:

```{r}
tweets <- stream_tweets(q = "election", timeout = 10)
head(tweets)
```

If we want, we could also export it to a csv file to be opened later with a spreadsheet program.
```{r}
write_as_csv(tweets, file_name = "election-streaming-tweets.csv")
```

And this is how we would capture tweets mentioning multiple keywords:
```{r, eval=FALSE}
tweets2 <- stream_tweets("biden AND election", timeout = 10)
head(tweets2$text)
```

We now turn to tweets collect filtering by location instead. To be able to apply this type of filter, we need to set a geographical box and collect only the tweets that are coming from that area.

For example, imagine we want to collect tweets from the United States. The way to do it is to find two pairs of coordinates (longitude and latitude) that indicate the southwest corner AND the northeast corner. Note the reverse order: it's not (lat, long), but (long, lat).

In the case of the US, it would be approx. (-125, 25) and (-66, 50). How to find these coordinates? You can use Google Maps, and right-click on the desired location. (Just note that long and lat are reversed here!)

```{r}
tweets <- stream_tweets(c(-125, 25, -66, 50), timeout = 10)
```

Now we can use the **maps** package to see where most tweets are coming from. Note that there are two types of geographic information on tweets: `lat`/`lon` (from geolocated tweets) and `place_lat` and `place_lon` (from tweets with place information). We will work with whatever is available.

```{r}
library("maps")
tweets <- lat_lng(tweets)

states <- map.where("state", tweets$lng, tweets$lat)
head(sort(table(states), decreasing = TRUE))
```

We can also prepare a map of the exact locations of the tweets.

```{r, fig.height=6, fig.width=10}
library("ggplot2")

## First create a data frame with the map data 
map.data <- map_data("state")

# And we use ggplot2 to draw the map:
# 1) map base
ggplot(map.data) + geom_map(aes(map_id = region), map = map.data, fill = "grey90", 
    color = "grey50", size = 0.25) + expand_limits(x = map.data$long, y = map.data$lat) + 
    # limits for x and y axis
    scale_x_continuous(limits=c(-125, -66)) + scale_y_continuous(limits = c(25, 50)) +
    # adding the dot for each tweet
    geom_point(data = tweets, aes(x = lng, y = lat), size = 5, 
               alpha = 1/5, color = "red") +
    # removing unnecessary graph elements
    theme(axis.line = element_blank(), 
    	axis.text = element_blank(), 
    	axis.ticks = element_blank(), 
        axis.title = element_blank(), 
        panel.background = element_blank(), 
        panel.border = element_blank(), 
        panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(), 
        plot.background = element_blank()) 
```

Finally, it's also possible to collect a random sample of tweets. That's what the "sampleStream" function does:

```{r}
rand_tweets <- stream_tweets(timeout = 30)
```

What is the most retweeted tweet?
```{r}
rand_tweets[which.max(rand_tweets$retweet_count), c("screen_name")]
rand_tweets[which.max(rand_tweets$retweet_count), c("text")]
```

What are the most popular hashtags at the moment? We'll use regular expressions to extract hashtags.
```{r}
library("stringr")
ht <- str_extract_all(rand_tweets$text, "#[A-Za-z0-9_]+")
ht <- unlist(ht)
head(sort(table(ht), decreasing = TRUE))
```

#### Storing and loading your own tokens

Once you have registered you can once store your tokens in a file. Copy them into the cell below and run it:

```{r, eval=FALSE}
authentication <- list(consumer_key = "cc08U6RfMu7oMy17fpH4hHGn6",
                 consumer_secret = "d9zQYlPyfqulZgMuNKrLLKXJOHiUBZqXb6VqGkaTLWMyKNTTd3",
                 access_token = "1320116969572544517-RMYWePAS4rCehQCyg11Gk6hPegGnDo",
                 access_token_secret = "WmCiv96sytceJlkl3a5ImXg6jEbkK5Dc3ZKnn12Pi4Bwi")
save(authentication, file = "authentication.rda")
```


# Authentication data
authentication = list()
authentication$consumer_key = "cc08U6RfMu7oMy17fpH4hHGn6"
authentication$consumer_secret = "d9zQYlPyfqulZgMuNKrLLKXJOHiUBZqXb6VqGkaTLWMyKNTTd3"
authentication$access_token = "1320116969572544517-RMYWePAS4rCehQCyg11Gk6hPegGnDo"
authentication$access_token_secret = "WmCiv96sytceJlkl3a5ImXg6jEbkK5Dc3ZKnn12Pi4Bwi"


To access this data, you can just run the following code in the future

```{r}
load("my_oauth.rda")
```

What can go wrong here? Make sure all the consumer and token keys are pasted here as is, without any additional space character. If you don't see any output in the console after running the code above, that's a good sign.

Note that the Oauth tokens data is saved as a local file.  That will save us some time later on, but you could also just re-run the code in lines 22 to 27 before connecting to the API in the future.
